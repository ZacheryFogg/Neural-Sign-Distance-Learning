{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Helpers.data import PointCloudDataset\n",
    "import Helpers.PointCloudOpen3d as pc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f'Using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4554\n"
     ]
    }
   ],
   "source": [
    "point_size = 1024\n",
    "object_classes=['stool', 'chair', 'tv_stand', 'bench', 'desk', 'sofa', 'wardrobe', 'toilet', 'table', 'sink', 'night_stand', 'mantel','dresser', 'bookshelf','bed']\n",
    "# train_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'train', object_classes=['stool', 'chair', 'tv_stand', 'bench', 'desk'])\n",
    "train_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'train', object_classes=object_classes)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'test', object_classes=object_classes)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "\n",
    "class ReadDataset(Dataset):\n",
    "    def __init__(self,  source):\n",
    "     \n",
    "        self.data = torch.from_numpy(source).float()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "def RandomSplit(datasets, train_set_percentage):\n",
    "    lengths = [int(len(datasets)*train_set_percentage), len(datasets)-int(len(datasets)*train_set_percentage)]\n",
    "    return random_split(datasets, lengths)\n",
    "\n",
    "def GetDataLoaders(npArray, batch_size, train_set_percentage = 0.9, shuffle=True, num_workers=0, pin_memory=True):\n",
    "    \n",
    "    \n",
    "    pc = ReadDataset(npArray)\n",
    "\n",
    "    train_set, test_set = RandomSplit(pc, train_set_percentage)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_set, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size, pin_memory=pin_memory)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "pc_array = np.load(\"../Data/chair_set.npy\")\n",
    "\n",
    "train_loader, test_loader = GetDataLoaders(npArray=pc_array, batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))[0]\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512])\n"
     ]
    }
   ],
   "source": [
    "feat = x.permute(0,2,1).clone()     # (3, 1024)\n",
    "c1 = nn.Conv1d(3, 16,1) # (16, 1024) - each point has been blown up from 3 to 16 numbers  \n",
    "c2 = nn.Conv1d(16, 32,1) # (32, 1024) - each point has been blown up from 16 to 32 numbers\n",
    "c3 = nn.Conv1d(32, 32, 7, stride=1, padding=3) # (32, 1024) - each activation is now an amalgamation of 7 neighboring points \n",
    "c4 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, 512) - each activation is now an amalgamation of roughly 49 neighboring points (is this right? )\n",
    "c5 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, 256)\n",
    "c6 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, 128)\n",
    "\n",
    "l1 = nn.Linear(4096, 2048)\n",
    "l2 = nn.Linear(2048, 512)\n",
    "\n",
    "o = c1(feat)\n",
    "o = c2(o)\n",
    "o = c3(o)\n",
    "o = c4(o)\n",
    "o = c5(o)\n",
    "o = c6(o)\n",
    "o = o.view(-1, 4096 )\n",
    "o = l1(o)\n",
    "lat = l2(o)\n",
    "\n",
    "print(lat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "dl1 = nn.Linear(512, 2048) # (2048)\n",
    "dl2 = nn.Linear(2048, 4096) # (4096)\n",
    "dc1 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 256)\n",
    "dc2 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 512)\n",
    "dc3 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding= 3) # (32, 1024)\n",
    "dc4 = nn.ConvTranspose1d(32, 32, 7, stride=1, padding= 3) # (32, 1024)\n",
    "dc5 = nn.ConvTranspose1d(32, 16, 1) # (16, 1024)\n",
    "dc6 = nn.ConvTranspose1d(16 ,3, 1) # (3, 1024)\n",
    "\n",
    "o = dl1(lat)\n",
    "o = dl2(o)\n",
    "o = o.view(32, 128)\n",
    "o = dc1(o)\n",
    "o = dc2(o)\n",
    "o = dc3(o)\n",
    "o = dc4(o)\n",
    "o = dc5(o)\n",
    "o = dc6(o)\n",
    "\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudAE(nn.Module):\n",
    "    def __init__(self, point_size, latent_size):\n",
    "        super(PointCloudAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        self.point_size = point_size\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, self.latent_size, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "        self.dec1 = nn.Linear(self.latent_size,256)\n",
    "        self.dec2 = nn.Linear(256,256)\n",
    "        self.dec3 = nn.Linear(256,self.point_size*3)\n",
    "\n",
    "    def encoder(self, x): \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, self.latent_size)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = self.dec3(x)\n",
    "        return x.view(-1, self.point_size, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module): \n",
    "    \n",
    "    def __init__(self, latent_dim, point_size):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.c1 = nn.Conv1d(3, 64,1) # (16, point_size) - each point has been blown up from 3 to 16 numbers  \n",
    "        self.c2 = nn.Conv1d(64, 128,1) # (32, point_size) - each point has been blown up from 16 to 32 numbers\n",
    "        self.c3 = nn.Conv1d(128, 32, 7, stride=1, padding=3) # (32, point_size) - each activation is now an amalgamation of 7 neighboring points \n",
    "        self.c4 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, point_size / 2) - each activation is now an amalgamation of roughly 49 neighboring points (is this right? )\n",
    "        self.c5 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, point_size / 4)\n",
    "        self.c6 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, point_size / 8)\n",
    "\n",
    "        self.lin7 = nn.Linear( int(point_size / 8) * 32, 2048)\n",
    "        self.lin8 = nn.Linear(2048, latent_dim)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.bn6 = nn.BatchNorm1d(32)\n",
    "        self.bn7 = nn.BatchNorm1d(2048)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.bn1(self.c1(x)))\n",
    "        x = F.gelu(self.bn2(self.c2(x)))\n",
    "        x = F.gelu(self.bn3(self.c3(x)))\n",
    "        x = F.gelu(self.bn4(self.c4(x)))\n",
    "        x = F.gelu(self.bn5(self.c5(x)))\n",
    "        x = F.gelu(self.bn6(self.c6(x)))\n",
    "\n",
    "        x = x.view(-1, int(point_size / 8) * 32 )\n",
    "\n",
    "        x = F.gelu(self.bn7(self.lin7(x)))\n",
    "        x = self.lin8(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# class ConvDecoder(nn.Module):\n",
    "    \n",
    "#     def __init__(self, latent_dim, point_size):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.point_size = point_size\n",
    "\n",
    "#         self.dl1 = nn.Linear(latent_dim, 2048) # (2048)\n",
    "#         self.dl2 = nn.Linear(2048, int(point_size / 8) * 32) # (4096)\n",
    "\n",
    "#         self.dc3 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 256)\n",
    "#         self.dc4 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 512)\n",
    "#         self.dc5 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding= 3) # (32, 1024)\n",
    "#         self.dc6 = nn.ConvTranspose1d(32, 128, 7, stride=1, padding= 3) # (32, 1024)\n",
    "#         self.dc7 = nn.ConvTranspose1d(128, 64, 1) # (16, 1024)\n",
    "#         self.dc8 = nn.ConvTranspose1d(64 ,3, 1) # (3, 1024)\n",
    "\n",
    "#         self.bn1 = nn.BatchNorm1d(2048)\n",
    "#         self.bn2 = nn.BatchNorm1d(4096)\n",
    "#         self.bn3 = nn.BatchNorm1d(32)\n",
    "#         self.bn4 = nn.BatchNorm1d(32)\n",
    "#         self.bn5 = nn.BatchNorm1d(32)\n",
    "#         self.bn6 = nn.BatchNorm1d(128)\n",
    "#         self.bn7 = nn.BatchNorm1d(64)\n",
    "\n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = F.gelu(self.bn1(self.dl1(x)))\n",
    "#         x = F.gelu(self.bn2(self.dl2(x)))\n",
    "\n",
    "#         x = x.view(-1, 32, int(self.point_size / 8))\n",
    "\n",
    "#         x = F.gelu(self.bn3(self.dc3(x)))\n",
    "#         x = F.gelu(self.bn4(self.dc4(x)))\n",
    "#         x = F.gelu(self.bn5(self.dc5(x)))\n",
    "#         x = F.gelu(self.bn6(self.dc6(x)))\n",
    "#         x = F.gelu(self.bn7(self.dc7(x)))\n",
    "#         x = F.gelu(self.dc8(x))\n",
    "\n",
    "#         return x\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim, point_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.point_size = point_size\n",
    "\n",
    "        self.l1 = nn.Linear(latent_dim, 768)\n",
    "        self.l2 = nn.Linear(768 , 1024)\n",
    "        self.l3 = nn.Linear(1024, 2048)\n",
    "        self.l4 = nn.Linear(2048, 3072)\n",
    "        self.l5 = nn.Linear(3072, point_size * 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.l1(x))\n",
    "        x = F.gelu(self.l2(x))\n",
    "        x = F.gelu(self.l3(x))\n",
    "        x = F.gelu(self.l4(x))\n",
    "        x = self.l5(x)\n",
    "        x = x.view(-1, self.point_size, 3)\n",
    "        return x    \n",
    "    \n",
    "class ConvAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, point_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = ConvEncoder(latent_dim, point_size)\n",
    "        self.decoder = ConvDecoder(latent_dim, point_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_rep = self.encoder(x)\n",
    "        recontructed_cloud = self.decoder(latent_rep)\n",
    "\n",
    "        return recontructed_cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PointCloudAE(nn.Module):\n",
    "#     def __init__(self, point_size, latent_size):\n",
    "#         super(PointCloudAE, self).__init__()\n",
    "        \n",
    "#         self.latent_size = latent_size\n",
    "#         self.point_size = point_size\n",
    "        \n",
    "#         self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "#         self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "#         self.conv3 = torch.nn.Conv1d(128, 256, 1)\n",
    "#         self.lin1 = nn.Linear(self.point_size, 512)\n",
    "#         self.lin2 = nn.Linear(512, self.latent_size)\n",
    "#         self.lin3 = nn.Linear(self.latent_size, 1)\n",
    "#         self.bn1 = nn.BatchNorm1d(64)\n",
    "#         self.bn2 = nn.BatchNorm1d(128)\n",
    "#         self.bn3 = nn.BatchNorm1d(256)\n",
    "#         # self.bn4 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "\n",
    "#         # self.dec1 = nn.Linear(self.latent_size,self.point_size)\n",
    "#         # self.dec2 = nn.Linear(self.point_size,2048)\n",
    "#         # self.dec3 = nn.Linear(2048, 3072)\n",
    "#         # self.dec4 = nn.Linear(3072,self.point_size*3)\n",
    "#         self.l1 = nn.Linear(latent_size, 768)\n",
    "#         self.l2 = nn.Linear(768 , 1024)\n",
    "#         self.l3 = nn.Linear(1024, 2048)\n",
    "#         self.l4 = nn.Linear(2048, 3072)\n",
    "#         self.l5 = nn.Linear(3072, point_size * 3)\n",
    "\n",
    "#     def encoder(self, x): \n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = F.relu(self.bn2(self.conv2(x)))\n",
    "#         x = F.relu(self.bn3(self.conv3(x)))\n",
    "#         # x = F.relu(self.bn4(self.lin1(x)))\n",
    "#         # x = F.relu(self.conv1(x))\n",
    "#         # x = F.relu(self.conv2(x))\n",
    "#         # x = F.relu(self.conv3(x))\n",
    "#         x = F.relu(self.lin1(x))\n",
    "#         x = F.relu(self.lin2(x))\n",
    "#         x = self.lin3(x)\n",
    "#         x = x.view(-1, self.latent_size)\n",
    "#         return x\n",
    "    \n",
    "#     def decoder(self, x):\n",
    "#         x = F.gelu(self.l1(x))\n",
    "#         x = F.gelu(self.l2(x))\n",
    "#         x = F.gelu(self.l3(x))\n",
    "#         x = F.gelu(self.l4(x))\n",
    "#         x = self.l5(x)\n",
    "#         x = x.view(-1, self.point_size, 3)\n",
    "#         return x    \n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "#         return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06706006771240097\n",
      "0.025645880171885856\n",
      "0.025403089463137664\n",
      "0.025319979167901553\n",
      "0.025318925842069663\n",
      "0.025146381893696692\n",
      "0.02512305573775218\n",
      "0.025114345829933882\n",
      "0.025073831148732167\n",
      "0.0250576319029698\n",
      "0.0249978808972698\n",
      "0.025031666163928233\n",
      "0.02495914944805778\n",
      "0.02490489102470187\n",
      "0.02485856958306753\n",
      "0.024827801156789064\n",
      "0.02480293348288307\n",
      "0.02474313469317097\n",
      "0.024723744987008665\n",
      "0.02466840809211135\n",
      "0.024639712180942297\n",
      "0.024576329697783176\n",
      "0.02459269518462511\n",
      "0.024537705852148626\n",
      "0.02451086613851098\n",
      "0.02446018198791605\n",
      "0.02443667698221711\n",
      "0.024421124289242122\n",
      "0.02438617465444482\n",
      "0.024374190288094375\n",
      "0.024355425212818842\n",
      "0.0243390233327563\n",
      "0.02429750020830677\n",
      "0.024289667928734653\n",
      "0.024279886820855048\n",
      "0.024255888178371467\n",
      "0.024214446401366822\n",
      "0.024189321145128746\n",
      "0.024162619804533627\n",
      "0.024174859030888632\n",
      "0.024138526847729318\n",
      "0.02414375887467311\n",
      "0.024104322127711315\n",
      "0.024080767403714932\n",
      "0.024089282700935237\n",
      "0.02406688020206415\n",
      "0.024042050998944502\n",
      "0.024019249213429596\n",
      "0.02400343557103322\n",
      "0.02396861263192617\n",
      "0.023946756568665687\n",
      "0.02395850419998169\n",
      "0.023941627882707577\n",
      "0.02393719392757003\n",
      "0.02391628283434189\n",
      "0.02391434833407402\n",
      "0.023887776017475586\n",
      "0.02389830626690617\n",
      "0.023877710318909243\n",
      "0.023854157600838404\n",
      "0.02387559811513011\n",
      "0.02383405102703434\n",
      "0.023818643011439305\n",
      "0.023823444552433033\n",
      "0.02380887343763159\n",
      "0.02378338514468991\n",
      "0.02378834393591835\n",
      "0.023781256821866218\n",
      "0.023788609470312413\n",
      "0.023756598086597826\n",
      "0.023786546626629736\n",
      "0.023761205948316134\n",
      "0.02375120626619229\n",
      "0.023743563761504796\n",
      "0.023720587532107647\n",
      "0.023703987889278393\n",
      "0.023690940131648228\n",
      "0.023717511015442703\n",
      "0.023698105440976527\n",
      "0.023714572585259493\n",
      "0.023684211970808413\n",
      "0.02367115318058775\n",
      "0.02366399199057084\n",
      "0.023678827171142284\n",
      "0.02366649491999012\n",
      "0.023669041979771394\n",
      "0.023642808378029328\n",
      "0.023676904957168378\n",
      "0.02364902771436251\n",
      "0.023658540135679338\n",
      "0.02364005008712411\n",
      "0.02364120904642802\n",
      "0.02362924122896332\n",
      "0.023637081317317028\n",
      "0.023610713282743327\n",
      "0.02361332832907255\n",
      "0.02362294702862318\n",
      "0.023604550685446996\n",
      "0.02360287896142556\n",
      "0.02361274417489767\n",
      "0.023583916195023518\n",
      "0.023579539838605203\n",
      "0.023589188483758614\n",
      "0.023617360991640732\n",
      "0.02359568367067438\n",
      "0.023627850871819716\n",
      "0.023565477297569696\n",
      "0.023550920869008854\n",
      "0.023590614302800253\n",
      "0.023549997104475133\n",
      "0.02355470683855506\n",
      "0.02353967955479255\n",
      "0.023544020449312832\n",
      "0.02354166140923133\n",
      "0.02354008758154053\n",
      "0.02351833167127692\n",
      "0.023539019354547445\n",
      "0.023530783382459328\n",
      "0.02354816085873888\n",
      "0.02351414394350006\n",
      "0.023496433089558896\n",
      "0.023492448676664095\n",
      "0.023488356481091335\n",
      "0.02351862371254426\n",
      "0.023505698459652755\n",
      "0.02351582544640853\n",
      "0.023517500000217788\n",
      "0.023495147112183846\n",
      "0.02350374200166418\n",
      "0.023480018206800405\n",
      "0.023489423884222142\n",
      "0.023501550133984823\n",
      "0.02348746216067901\n",
      "0.02348997014073225\n",
      "0.02347875078423665\n",
      "0.023471397634309072\n",
      "0.023473383894620035\n",
      "0.02344764847881519\n",
      "0.0234629581324183\n",
      "0.023442907223048117\n",
      "0.023466774477408484\n",
      "0.02345620672433422\n",
      "0.023446014616638422\n",
      "0.023446637814721234\n",
      "0.02345652853210385\n",
      "0.023428697497225724\n",
      "0.02344295808758873\n",
      "0.02343820407986641\n",
      "0.02344490813377958\n",
      "0.023421417420300152\n",
      "0.023418920365377113\n",
      "0.023425879422575235\n",
      "0.02343347493129281\n",
      "0.02345209027855442\n",
      "0.02342391537072567\n",
      "0.023414789591557704\n",
      "0.023415442985983994\n",
      "0.023427220312162086\n",
      "0.023398875294683073\n",
      "0.023390685100681506\n",
      "0.023399054968299773\n",
      "0.023411376759983026\n",
      "0.023406407401825372\n",
      "0.023408860039825622\n",
      "0.023397395351471808\n",
      "0.023386157905826203\n",
      "0.02339283427080283\n",
      "0.02341303540966832\n",
      "0.023390179571623985\n",
      "0.023385883774608374\n",
      "0.02338887149324784\n",
      "0.02339112525805831\n",
      "0.023372729452183612\n",
      "0.023382386515060298\n",
      "0.02338107514123504\n",
      "0.023400900312341176\n",
      "0.023365979835104484\n",
      "0.023388945819953315\n",
      "0.02336327187143839\n",
      "0.023362067957910206\n",
      "0.02335591145003071\n",
      "0.023355976606790837\n",
      "0.02336021476926712\n",
      "0.023356520785735205\n",
      "0.023346680753792707\n",
      "0.023347838710133847\n",
      "0.023338373069866344\n",
      "0.02336075773032812\n",
      "0.023358404493102662\n",
      "0.023344039272230405\n",
      "0.023333396332768295\n",
      "0.02332606865093112\n",
      "0.023335835000929925\n",
      "0.02334884052666334\n",
      "0.023319790712915935\n",
      "0.023322805654830657\n",
      "0.023328972837099664\n",
      "0.02334085160579819\n",
      "0.023322652774648026\n",
      "0.02334635045665961\n",
      "0.02331549792478864\n",
      "0.0233147325567328\n",
      "0.023323483657664977\n",
      "0.02331377247061867\n",
      "0.02332808242107813\n",
      "0.023317105853213713\n",
      "0.023309579799668148\n",
      "0.023315289021971133\n",
      "0.023353193528377093\n",
      "0.02331436103066573\n",
      "0.023312181126899444\n",
      "0.02330689078483444\n",
      "0.023296507361989755\n",
      "0.023298232744519528\n",
      "0.023300335491792515\n",
      "0.02329240531588976\n",
      "0.02331203010936196\n",
      "0.02329168740946513\n",
      "0.023291033083716266\n",
      "0.023283506492869213\n",
      "0.023293877521959636\n",
      "0.023295816571380083\n",
      "0.023310696240514517\n",
      "0.023319146774995785\n",
      "0.02328808157919691\n",
      "0.023275250354065344\n",
      "0.0232784035615623\n",
      "0.023279604215461474\n",
      "0.023281427565962076\n",
      "0.023285047473529212\n",
      "0.023280437355144665\n",
      "0.023268333815324765\n",
      "0.023284409159364607\n",
      "0.02326874753746849\n",
      "0.023285927716642618\n",
      "0.02330507904004592\n",
      "0.023280601482838392\n",
      "0.023265005125162695\n",
      "0.02327639552263113\n",
      "0.0232662595808506\n",
      "0.023265220296497528\n",
      "0.023239046693421327\n",
      "0.023265750971264564\n",
      "0.02327989561196703\n",
      "0.023265981366141483\n",
      "0.02327614675204341\n",
      "0.023241277497548323\n",
      "0.023273309370359548\n",
      "0.02326891145024162\n",
      "0.023240876133338764\n",
      "0.023267456616919775\n",
      "0.02326163248373912\n",
      "0.023251724465248678\n",
      "0.02325572342110368\n",
      "0.023264879647355814\n",
      "0.023236974357412413\n",
      "0.0232360502346777\n",
      "0.02325109700457408\n",
      "0.023252625842220508\n",
      "0.023268534013858207\n",
      "0.023277709224762824\n",
      "0.023238783021672413\n",
      "0.02325262580640041\n",
      "0.02324031597863023\n",
      "0.02325065158164272\n",
      "0.023231137866297595\n",
      "0.023250206875113342\n",
      "0.023236731676241525\n",
      "0.02322692101678023\n",
      "0.023238489905802105\n",
      "0.023245211189182904\n",
      "0.023229816606125005\n",
      "0.023223742341192868\n",
      "0.0232439823090457\n",
      "0.023251332270984467\n",
      "0.02323919416476901\n",
      "0.023224812287550706\n",
      "0.02322787680448248\n",
      "0.023207033088860605\n",
      "0.023231901586628877\n",
      "0.02323619810004647\n",
      "0.02322001174951975\n",
      "0.02320547538021436\n",
      "0.023235414571200427\n",
      "0.02321712214213151\n",
      "0.023238634726462457\n",
      "0.02323543828410598\n",
      "0.023219470507823504\n",
      "0.02318799155406081\n",
      "0.023211254344250146\n",
      "0.023219896874462184\n",
      "0.023219191576712407\n",
      "0.023210470313922718\n",
      "0.023221274408010337\n",
      "0.02325209964496585\n",
      "0.023206822359218046\n",
      "0.02321641856374649\n",
      "0.023222422334723748\n",
      "0.023215486811330684\n",
      "0.02320669061289384\n",
      "0.023209485440300062\n",
      "0.023191935669344205\n",
      "0.023211396800783966\n",
      "0.02320022053586749\n",
      "0.023204178155328218\n",
      "0.02320587900109016\n",
      "0.023189059566133298\n",
      "0.023196661558288794\n",
      "0.023179341215067185\n",
      "0.023190349519539338\n",
      "0.02318556012155918\n",
      "0.02319512623720444\n",
      "0.02319609782157036\n",
      "0.023192537339547507\n",
      "0.023191370714742403\n",
      "0.023206481745896432\n",
      "0.023203287166185103\n",
      "0.023200470989999864\n",
      "0.023187873061173238\n",
      "0.02318335406912061\n",
      "0.023188475125397626\n",
      "0.0231821730446357\n",
      "0.023183691781014204\n",
      "0.023179841836771138\n",
      "0.02318462883480466\n",
      "0.023163133014280062\n",
      "0.023175804410129786\n",
      "0.023179648587336905\n",
      "0.023186309442210656\n",
      "0.023177260246414404\n",
      "0.02318362730483596\n",
      "0.02317353506357624\n",
      "0.023159568054744832\n",
      "0.023180659860372543\n",
      "0.023163319314615086\n",
      "0.023163396005447093\n",
      "0.023160502780228853\n",
      "0.023161859538119573\n",
      "0.023172987839923456\n",
      "0.02317147282883525\n",
      "0.023168468059828647\n",
      "0.023162648153419677\n",
      "0.023161642504139587\n",
      "0.02317763675147524\n",
      "0.023157517354075726\n",
      "0.023163253333992682\n",
      "0.023149618305839025\n",
      "0.023170242157693092\n",
      "0.023181387223303318\n",
      "0.023156398584922917\n",
      "0.023148492229386017\n",
      "0.02314149119103184\n",
      "0.02314176639685264\n",
      "0.02315805909725336\n",
      "0.023153020069003105\n",
      "0.023134043583503135\n",
      "0.023139709176925514\n",
      "0.023140627066962995\n",
      "0.023164182901382446\n",
      "0.023141770229603235\n",
      "0.02315598292849385\n",
      "0.023134125074228414\n",
      "0.023151141985391196\n",
      "0.02315541675600868\n",
      "0.023123149186945878\n",
      "0.023138720721292954\n",
      "0.023121625041732423\n",
      "0.02311639326552932\n",
      "0.023133142600552395\n",
      "0.023137338244571135\n",
      "0.023118131471654542\n",
      "0.023132505504271157\n",
      "0.023122043098108128\n",
      "0.02311221556738019\n",
      "0.023096851717967253\n",
      "0.023112682840571955\n",
      "0.023099878193953864\n",
      "0.02310101193590806\n",
      "0.023096449171694424\n",
      "0.023112329009633798\n",
      "0.02309813006566121\n",
      "0.023095093309306182\n",
      "0.023090856042332374\n",
      "0.023098458643429555\n",
      "0.02308414403635722\n",
      "0.023091553423840266\n",
      "0.02307752466115814\n",
      "0.023072281207602758\n",
      "0.023075751709536865\n",
      "0.02305825534634865\n",
      "0.023084751007935174\n",
      "0.023070157039910555\n",
      "0.023085591634019062\n",
      "0.023058337446015615\n",
      "0.02306123024139267\n",
      "0.023046157251183804\n",
      "0.023044539866252586\n",
      "0.023046486294613436\n",
      "0.023036812181369618\n",
      "0.023041969093565758\n",
      "0.02304356126114726\n",
      "0.023019025066437628\n",
      "0.0230130715868794\n",
      "0.022994013789754648\n",
      "0.02300811795374522\n",
      "0.022985493943381768\n",
      "0.022978818151526727\n",
      "0.02296912043283765\n",
      "0.02298359114390153\n",
      "0.022958997601213362\n",
      "0.02294534523613178\n",
      "0.02296313403460842\n",
      "0.022978117438749626\n",
      "0.022944100165309813\n",
      "0.022950986650987312\n",
      "0.022966173119269885\n",
      "0.02293403923081664\n",
      "0.022946557495743036\n",
      "0.022944978509957973\n",
      "0.02292564919648262\n",
      "0.022926806185681086\n",
      "0.022909903827194985\n",
      "0.022942993933191665\n",
      "0.02289128923215545\n",
      "0.022897535254462406\n",
      "0.022897108386342343\n",
      "0.022904481308964584\n",
      "0.022922286656326972\n",
      "0.022906772541598633\n",
      "0.022895624108899098\n",
      "0.022889802053284187\n",
      "0.02291618026076601\n",
      "0.022902036730486613\n",
      "0.022878248065423507\n",
      "0.02289013736523115\n",
      "0.022882746854940288\n",
      "0.022872667365635816\n",
      "0.022853034906662427\n",
      "0.022849633394239042\n",
      "0.02286706682151327\n",
      "0.02286311364374482\n",
      "0.022842429864865083\n",
      "0.022839964976390965\n",
      "0.022835317855844132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[191], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m) :\n\u001b[0;32m     37\u001b[0m     startTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 39\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#train one epoch, get the average loss\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     43\u001b[0m     epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m startTime\n",
      "Cell \u001b[1;32mIn[191], line 12\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_epoch\u001b[39m():\n\u001b[0;32m     11\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     13\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# x = data['points'].to(device)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# net = PointCloudAE2(point_size, 768).to(device)\n",
    "# net = PointCloudAE(1024, 256).to(device)\n",
    "# net = ConvAutoEncoder(512, 1024).to(device)\n",
    "\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance # chamfer distance for calculating point cloud distance\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "\n",
    "def train_epoch():\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # x = data['points'].to(device)\n",
    "        x = data.to(device)\n",
    "\n",
    "        output = net(x.permute(0,2,1)) # transpose data for NumberxChannelxSize format\n",
    "\n",
    "        # print(x.shape, output.shape)\n",
    "        loss, _ = chamfer_distance(x, output) \n",
    "        # loss = F.mse_loss(x, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    if i == 0:\n",
    "        return epoch_loss / 1\n",
    "    return epoch_loss/i\n",
    "\n",
    "\n",
    "train_loss_list = []  \n",
    "test_loss_list = []  \n",
    "\n",
    "for i in range(10000) :\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    train_loss = train_epoch() #train one epoch, get the average loss\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    \n",
    "    epoch_time = time.time() - startTime\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_models/furniture_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'trained_models/furniture_model_weights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('trained_models/furniture_model_weights_50k', weights_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))[0]\n",
    "\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "    rec_x = np.array(model(data)[0].to('cpu'))\n",
    "    cloud = pc.get_point_cloud(rec_x)\n",
    "    pc.visualize_point_cloud(cloud)\n",
    "# x = next(iter(train_loader))['points'][0]\n",
    "\n",
    "# cloud = pc.get_point_cloud(x)\n",
    "# pc.visualize_point_cloud(cloud)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "#     rec_x = np.array(model(data)[0].to('cpu'))\n",
    "#     cloud = pc.get_point_cloud(rec_x)\n",
    "#     pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x2048 and 1024x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m     rec_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     11\u001b[0m     cloud \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mget_point_cloud(rec_x)\n\u001b[0;32m     12\u001b[0m     pc\u001b[38;5;241m.\u001b[39mvisualize_point_cloud(cloud)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[157], line 54\u001b[0m, in \u001b[0;36mPointCloudAE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 54\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[1;32mIn[157], line 38\u001b[0m, in \u001b[0;36mPointCloudAE.encoder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# x = F.relu(self.bn4(self.lin1(x)))\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# x = F.relu(self.conv1(x))\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# x = F.relu(self.conv2(x))\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# x = F.relu(self.conv3(x))\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x))\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin3(x)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x2048 and 1024x512)"
     ]
    }
   ],
   "source": [
    "model = net\n",
    "x = next(iter(test_loader))['points'][0]\n",
    "\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "    rec_x = np.array(model(data)[0].to('cpu'))\n",
    "    cloud = pc.get_point_cloud(rec_x)\n",
    "    pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4817, 0.6104, 0.3859],\n",
      "        [0.4709, 0.6067, 0.4072],\n",
      "        [0.4908, 0.6125, 0.3900],\n",
      "        ...,\n",
      "        [0.5262, 0.5955, 0.4208],\n",
      "        [0.5483, 0.8067, 0.4412],\n",
      "        [0.5769, 0.8080, 0.4399]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = next(iter(train_loader))['points'][0]\n",
    "\n",
    "# print(x[:,i].min())\n",
    "x_min = x.min()\n",
    "x_max = x.max()\n",
    "\n",
    "x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "cloud = pc.get_point_cloud(x_norm)\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "print(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5825, 0.5014, 0.1379],\n",
       "        [0.5915, 0.4976, 0.1370],\n",
       "        [0.8215, 0.3296, 0.1172],\n",
       "        ...,\n",
       "        [0.6037, 0.3774, 0.0789],\n",
       "        [0.6028, 0.3761, 0.0731],\n",
       "        [0.6030, 0.3761, 0.0733]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_size = 768\n",
    "train_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'train', object_classes=['stool', 'chair', 'tv_stand', 'bench', 'desk'])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "class PointCloudAE(nn.Module):\n",
    "    def __init__(self, point_size, latent_size):\n",
    "        super(PointCloudAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        self.point_size = point_size\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 256, 1)\n",
    "        self.lin1 = nn.Linear(self.point_size, self.latent_size)\n",
    "        self.lin2 = nn.Linear(self.latent_size, 1)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.bn2 = nn.BatchNorm1d(256)\n",
    "        # self.bn3 = nn.BatchNorm1d(256)\n",
    "        # self.bn4 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "\n",
    "        self.dec1 = nn.Linear(self.latent_size,self.point_size)\n",
    "        self.dec2 = nn.Linear(self.point_size,2048)\n",
    "        self.dec3 = nn.Linear(2048, 3072)\n",
    "        self.dec4 = nn.Linear(3072,self.point_size*3)\n",
    "\n",
    "    def encoder(self, x): \n",
    "        # x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # x = F.relu(self.bn3(self.conv3(x)))\n",
    "        # x = F.relu(self.bn4(self.lin1(x)))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        x = x.view(-1, self.latent_size)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = self.dec4(x)\n",
    "        x = x.view(-1, self.point_size, 3)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "78f5f5f49bfb79eff1b75f7af9e6efc3fcb545b54f444bc1ad589308dff7b92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
