{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Helpers.data import PointCloudDataset\n",
    "import Helpers.PointCloudOpen3d as pc\n",
    "from Helpers.data2 import PointCloudDataset2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f'Using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2316\n"
     ]
    }
   ],
   "source": [
    "point_size = 1024\n",
    "# object_classes=['stool', 'chair', 'tv_stand', 'bench', 'desk', 'sofa', 'wardrobe', 'toilet', 'table', 'sink', 'night_stand', 'mantel','dresser', 'bookshelf','bed']\n",
    "# object_classes=['stool', 'chair', 'bench', 'desk', 'table', 'night_stand', 'bookshelf']\n",
    "# train_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'train', object_classes=['stool', 'chair', 'tv_stand', 'bench', 'desk'])\n",
    "train_dataset = PointCloudDataset2(\"../Data/ModelNet40\", point_size, 'train', object_classes=object_classes)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PointCloudDataset2(\"../Data/ModelNet40\", point_size, 'test', object_classes=object_classes)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "\n",
    "class ReadDataset(Dataset):\n",
    "    def __init__(self,  source):\n",
    "     \n",
    "        self.data = torch.from_numpy(source).float()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "def RandomSplit(datasets, train_set_percentage):\n",
    "    lengths = [int(len(datasets)*train_set_percentage), len(datasets)-int(len(datasets)*train_set_percentage)]\n",
    "    return random_split(datasets, lengths)\n",
    "\n",
    "def GetDataLoaders(npArray, batch_size, train_set_percentage = 0.9, shuffle=True, num_workers=0, pin_memory=True):\n",
    "    \n",
    "    \n",
    "    pc = ReadDataset(npArray)\n",
    "\n",
    "    train_set, test_set = RandomSplit(pc, train_set_percentage)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_set, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size, pin_memory=pin_memory)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "pc_array = np.load(\"../Data/chair_set.npy\")\n",
    "\n",
    "train_loader, test_loader = GetDataLoaders(npArray=pc_array, batch_size= 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m cloud \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mget_point_cloud(x)\n\u001b[0;32m      3\u001b[0m pc\u001b[38;5;241m.\u001b[39mvisualize_point_cloud(cloud)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "x = next(iter(train_loader))[0]\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512])\n"
     ]
    }
   ],
   "source": [
    "feat = x.permute(0,2,1).clone()     # (3, 1024)\n",
    "c1 = nn.Conv1d(3, 16,1) # (16, 1024) - each point has been blown up from 3 to 16 numbers  \n",
    "c2 = nn.Conv1d(16, 32,1) # (32, 1024) - each point has been blown up from 16 to 32 numbers\n",
    "c3 = nn.Conv1d(32, 32, 7, stride=1, padding=3) # (32, 1024) - each activation is now an amalgamation of 7 neighboring points \n",
    "c4 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, 512) - each activation is now an amalgamation of roughly 49 neighboring points (is this right? )\n",
    "c5 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, 256)\n",
    "c6 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, 128)\n",
    "\n",
    "l1 = nn.Linear(4096, 2048)\n",
    "l2 = nn.Linear(2048, 512)\n",
    "\n",
    "o = c1(feat)\n",
    "o = c2(o)\n",
    "o = c3(o)\n",
    "o = c4(o)\n",
    "o = c5(o)\n",
    "o = c6(o)\n",
    "o = o.view(-1, 4096 )\n",
    "o = l1(o)\n",
    "lat = l2(o)\n",
    "\n",
    "print(lat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n"
     ]
    }
   ],
   "source": [
    "dl1 = nn.Linear(512, 2048) # (2048)\n",
    "dl2 = nn.Linear(2048, 4096) # (4096)\n",
    "dc1 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 256)\n",
    "dc2 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 512)\n",
    "dc3 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding= 3) # (32, 1024)\n",
    "dc4 = nn.ConvTranspose1d(32, 32, 7, stride=1, padding= 3) # (32, 1024)\n",
    "dc5 = nn.ConvTranspose1d(32, 16, 1) # (16, 1024)\n",
    "dc6 = nn.ConvTranspose1d(16 ,3, 1) # (3, 1024)\n",
    "\n",
    "o = dl1(lat)\n",
    "o = dl2(o)\n",
    "o = o.view(32, 128)\n",
    "o = dc1(o)\n",
    "o = dc2(o)\n",
    "o = dc3(o)\n",
    "o = dc4(o)\n",
    "o = dc5(o)\n",
    "o = dc6(o)\n",
    "\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudAE(nn.Module):\n",
    "    def __init__(self, point_size, latent_size):\n",
    "        super(PointCloudAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        self.point_size = point_size\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, self.latent_size, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "        self.dec1 = nn.Linear(self.latent_size,256)\n",
    "        self.dec2 = nn.Linear(256,256)\n",
    "        self.dec3 = nn.Linear(256,self.point_size*3)\n",
    "\n",
    "    def encoder(self, x): \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, self.latent_size)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = self.dec3(x)\n",
    "        return x.view(-1, self.point_size, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module): \n",
    "    \n",
    "    def __init__(self, latent_dim, point_size):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.c1 = nn.Conv1d(3, 64,1) # (16, point_size) - each point has been blown up from 3 to 16 numbers  \n",
    "        self.c2 = nn.Conv1d(64, 128,1) # (32, point_size) - each point has been blown up from 16 to 32 numbers\n",
    "        self.c3 = nn.Conv1d(128, 32, 7, stride=1, padding=3) # (32, point_size) - each activation is now an amalgamation of 7 neighboring points \n",
    "        self.c4 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, point_size / 2) - each activation is now an amalgamation of roughly 49 neighboring points (is this right? )\n",
    "        self.c5 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, point_size / 4)\n",
    "        self.c6 = nn.Conv1d(32, 32, 7, stride=2, padding=3) # (32, point_size / 8)\n",
    "\n",
    "        self.lin7 = nn.Linear( int(point_size / 8) * 32, 2048)\n",
    "        self.lin8 = nn.Linear(2048, latent_dim)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.bn6 = nn.BatchNorm1d(32)\n",
    "        self.bn7 = nn.BatchNorm1d(2048)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.gelu(self.bn1(self.c1(x)))\n",
    "        x = F.gelu(self.bn2(self.c2(x)))\n",
    "        x = F.gelu(self.bn3(self.c3(x)))\n",
    "        x = F.gelu(self.bn4(self.c4(x)))\n",
    "        x = F.gelu(self.bn5(self.c5(x)))\n",
    "        x = F.gelu(self.bn6(self.c6(x)))\n",
    "\n",
    "        x = x.view(-1, int(point_size / 8) * 32 )\n",
    "\n",
    "        x = F.gelu(self.bn7(self.lin7(x)))\n",
    "        x = self.lin8(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim, point_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.point_size = point_size\n",
    "\n",
    "        self.dl1 = nn.Linear(latent_dim, 2048) # (2048)\n",
    "        self.dl2 = nn.Linear(2048, int(point_size / 8) * 32) # (4096)\n",
    "\n",
    "        self.dc3 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 256)\n",
    "        self.dc4 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding = 3) # (32, 512)\n",
    "        self.dc5 = nn.ConvTranspose1d(32, 32, 8, stride=2, padding= 3) # (32, 1024)\n",
    "        self.dc6 = nn.ConvTranspose1d(32, 128, 7, stride=1, padding= 3) # (32, 1024)\n",
    "        self.dc7 = nn.ConvTranspose1d(128, 64, 1) # (16, 1024)\n",
    "        self.dc8 = nn.ConvTranspose1d(64 ,3, 1) # (3, 1024)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.bn2 = nn.BatchNorm1d(4096)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.bn6 = nn.BatchNorm1d(128)\n",
    "        self.bn7 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.gelu(self.bn1(self.dl1(x)))\n",
    "        x = F.gelu(self.bn2(self.dl2(x)))\n",
    "\n",
    "        x = x.view(-1, 32, int(self.point_size / 8))\n",
    "\n",
    "        x = F.gelu(self.bn3(self.dc3(x)))\n",
    "        x = F.gelu(self.bn4(self.dc4(x)))\n",
    "        x = F.gelu(self.bn5(self.dc5(x)))\n",
    "        x = F.gelu(self.bn6(self.dc6(x)))\n",
    "        x = F.gelu(self.bn7(self.dc7(x)))\n",
    "        x = F.gelu(self.dc8(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# class ConvDecoder(nn.Module):\n",
    "    \n",
    "#     def __init__(self, latent_dim, point_size):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.point_size = point_size\n",
    "\n",
    "#         self.l1 = nn.Linear(latent_dim, 768)\n",
    "#         self.l2 = nn.Linear(768 , 1024)\n",
    "#         self.l3 = nn.Linear(1024, 2048)\n",
    "#         self.l4 = nn.Linear(2048, 3072)\n",
    "#         self.l5 = nn.Linear(3072, point_size * 3)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.gelu(self.l1(x))\n",
    "#         x = F.gelu(self.l2(x))\n",
    "#         x = F.gelu(self.l3(x))\n",
    "#         x = F.gelu(self.l4(x))\n",
    "#         x = self.l5(x)\n",
    "#         x = x.view(-1, self.point_size, 3)\n",
    "#         return x    \n",
    "    \n",
    "class ConvAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, point_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = ConvEncoder(latent_dim, point_size)\n",
    "        self.decoder = ConvDecoder(latent_dim, point_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_rep = self.encoder(x)\n",
    "        recontructed_cloud = self.decoder(latent_rep)\n",
    "\n",
    "        return recontructed_cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PointCloudAE(nn.Module):\n",
    "#     def __init__(self, point_size, latent_size):\n",
    "#         super(PointCloudAE, self).__init__()\n",
    "        \n",
    "#         self.latent_size = latent_size\n",
    "#         self.point_size = point_size\n",
    "        \n",
    "#         self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "#         self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "#         self.conv3 = torch.nn.Conv1d(128, 256, 1)\n",
    "#         self.lin1 = nn.Linear(self.point_size, 512)\n",
    "#         self.lin2 = nn.Linear(512, self.latent_size)\n",
    "#         self.lin3 = nn.Linear(self.latent_size, 1)\n",
    "#         self.bn1 = nn.BatchNorm1d(64)\n",
    "#         self.bn2 = nn.BatchNorm1d(128)\n",
    "#         self.bn3 = nn.BatchNorm1d(256)\n",
    "#         # self.bn4 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "\n",
    "#         # self.dec1 = nn.Linear(self.latent_size,self.point_size)\n",
    "#         # self.dec2 = nn.Linear(self.point_size,2048)\n",
    "#         # self.dec3 = nn.Linear(2048, 3072)\n",
    "#         # self.dec4 = nn.Linear(3072,self.point_size*3)\n",
    "#         self.l1 = nn.Linear(latent_size, 768)\n",
    "#         self.l2 = nn.Linear(768 , 1024)\n",
    "#         self.l3 = nn.Linear(1024, 2048)\n",
    "#         self.l4 = nn.Linear(2048, 3072)\n",
    "#         self.l5 = nn.Linear(3072, point_size * 3)\n",
    "\n",
    "#     def encoder(self, x): \n",
    "#         x = F.relu(self.bn1(self.conv1(x)))\n",
    "#         x = F.relu(self.bn2(self.conv2(x)))\n",
    "#         x = F.relu(self.bn3(self.conv3(x)))\n",
    "#         # x = F.relu(self.bn4(self.lin1(x)))\n",
    "#         # x = F.relu(self.conv1(x))\n",
    "#         # x = F.relu(self.conv2(x))\n",
    "#         # x = F.relu(self.conv3(x))\n",
    "#         x = F.relu(self.lin1(x))\n",
    "#         x = F.relu(self.lin2(x))\n",
    "#         x = self.lin3(x)\n",
    "#         x = x.view(-1, self.latent_size)\n",
    "#         return x\n",
    "    \n",
    "#     def decoder(self, x):\n",
    "#         x = F.gelu(self.l1(x))\n",
    "#         x = F.gelu(self.l2(x))\n",
    "#         x = F.gelu(self.l3(x))\n",
    "#         x = F.gelu(self.l4(x))\n",
    "#         x = self.l5(x)\n",
    "#         x = x.view(-1, self.point_size, 3)\n",
    "#         return x    \n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x = self.decoder(x)\n",
    "#         return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train_loss: 0.21064065614094338\n",
      "Epoch 100 Train_loss: 0.004587396824111541\n",
      "Epoch 200 Train_loss: 0.05521578429680732\n",
      "Epoch 300 Train_loss: 0.04236642374760575\n",
      "Epoch 400 Train_loss: 0.031202187968624964\n",
      "Epoch 500 Train_loss: 0.019640171978001792\n",
      "Epoch 600 Train_loss: 0.01035538508505043\n",
      "Epoch 700 Train_loss: 0.0057365721376198865\n",
      "Epoch 800 Train_loss: 0.0038459196221083403\n",
      "Epoch 900 Train_loss: 0.003203008556738496\n",
      "Epoch 1000 Train_loss: 0.0028051960398443043\n",
      "Epoch 1100 Train_loss: 0.00195270146165664\n",
      "Epoch 1200 Train_loss: 0.0014606259679163082\n",
      "Epoch 1300 Train_loss: 0.001377678460105219\n",
      "Epoch 1400 Train_loss: 0.001383946047604291\n",
      "Epoch 1500 Train_loss: 0.0009551183983502495\n",
      "Epoch 1600 Train_loss: 0.0029989111482993597\n",
      "Epoch 1700 Train_loss: 0.0021191561213021893\n",
      "Epoch 1800 Train_loss: 0.0014566939369413173\n",
      "Epoch 1900 Train_loss: 0.001128835551854637\n",
      "Epoch 2000 Train_loss: 0.0010564515186059806\n",
      "Epoch 2100 Train_loss: 0.000891223844114898\n",
      "Epoch 2200 Train_loss: 0.0009307136497227475\n",
      "Epoch 2300 Train_loss: 0.0006988049895476757\n",
      "Epoch 2400 Train_loss: 0.0006071195368551546\n",
      "Epoch 2500 Train_loss: 0.000573110512858774\n",
      "Epoch 2600 Train_loss: 0.0007030137332751312\n",
      "Epoch 2700 Train_loss: 0.00306161910864628\n",
      "Epoch 2800 Train_loss: 0.0020915174811509335\n",
      "Epoch 2900 Train_loss: 0.0013487314313857092\n",
      "Epoch 3000 Train_loss: 0.0011792420813839675\n",
      "Epoch 3100 Train_loss: 0.0008247868778804938\n",
      "Epoch 3200 Train_loss: 0.0009161016674220769\n",
      "Epoch 3300 Train_loss: 0.0006395071330997678\n",
      "Epoch 3400 Train_loss: 0.0006471836289468532\n",
      "Epoch 3500 Train_loss: 0.0005803686476105617\n",
      "Epoch 3600 Train_loss: 0.0007167809186891342\n",
      "Epoch 3700 Train_loss: 0.00218852401465281\n",
      "Epoch 3800 Train_loss: 0.0015052486269269139\n",
      "Epoch 3900 Train_loss: 0.000981691456723234\n",
      "Epoch 4000 Train_loss: 0.000901195164058461\n",
      "Epoch 4100 Train_loss: 0.004681589250038896\n",
      "Epoch 4200 Train_loss: 0.0013846957655106154\n",
      "Epoch 4300 Train_loss: 0.0010748056358554298\n",
      "Epoch 4400 Train_loss: 0.0020121247087243116\n",
      "Epoch 4500 Train_loss: 0.0009511201011870677\n",
      "Epoch 4600 Train_loss: 0.0006621345188856745\n",
      "Epoch 4700 Train_loss: 0.0015595413699176991\n",
      "Epoch 4800 Train_loss: 0.000721418360222338\n",
      "Epoch 4900 Train_loss: 0.000546186839023398\n",
      "Epoch 5000 Train_loss: 0.008858159313806228\n",
      "Epoch 5100 Train_loss: 0.005482803008312153\n",
      "Epoch 5200 Train_loss: 0.004441557827198671\n",
      "Epoch 5300 Train_loss: 0.0038507231381825274\n",
      "Epoch 5400 Train_loss: 0.0033188001511411536\n",
      "Epoch 5500 Train_loss: 0.002993521093028701\n",
      "Epoch 5600 Train_loss: 0.002391770511167124\n",
      "Epoch 5700 Train_loss: 0.004968129887452556\n",
      "Epoch 5800 Train_loss: 0.003700005893026375\n",
      "Epoch 5900 Train_loss: 0.0029313265048484835\n",
      "Epoch 6000 Train_loss: 0.002219904003949422\n",
      "Epoch 6100 Train_loss: 0.001868728037354433\n",
      "Epoch 6200 Train_loss: 0.0013506035352798386\n",
      "Epoch 6300 Train_loss: 0.0016303524284416602\n",
      "Epoch 6400 Train_loss: 0.0011522663537309403\n",
      "Epoch 6500 Train_loss: 0.009959476922328273\n",
      "Epoch 6600 Train_loss: 0.006826462269398487\n",
      "Epoch 6700 Train_loss: 0.009263403894793656\n",
      "Epoch 6800 Train_loss: 0.005393160397135135\n",
      "Epoch 6900 Train_loss: 0.00417932752882027\n",
      "Epoch 7000 Train_loss: 0.0032311793119232687\n",
      "Epoch 7100 Train_loss: 0.0027251330320723355\n",
      "Epoch 7200 Train_loss: 0.002285139929477332\n",
      "Epoch 7300 Train_loss: 0.0018837803315060835\n",
      "Epoch 7400 Train_loss: 0.0014951362391002476\n",
      "Epoch 7500 Train_loss: 0.0013581090736099416\n",
      "Epoch 7600 Train_loss: 0.0009259257413860825\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m) :\n\u001b[0;32m     37\u001b[0m     startTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 39\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#train one epoch, get the average loss\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     43\u001b[0m     epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m startTime\n",
      "Cell \u001b[1;32mIn[70], line 20\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m net(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# transpose data for NumberxChannelxSize format\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(x.shape, output.shape)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mchamfer_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# loss = F.mse_loss(x, output)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\pytorch3d\\loss\\chamfer.py:265\u001b[0m, in \u001b[0;36mchamfer_distance\u001b[1;34m(x, y, x_lengths, y_lengths, x_normals, y_normals, weights, batch_reduction, point_reduction, norm, single_directional, abs_cosine)\u001b[0m\n\u001b[0;32m    263\u001b[0m     loss_normals \u001b[38;5;241m=\u001b[39m cham_norm_x\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     cham_y, cham_norm_y \u001b[38;5;241m=\u001b[39m \u001b[43m_chamfer_distance_single_direction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_normals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_normals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_reduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_cosine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m point_reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    278\u001b[0m         loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmaximum(cham_x, cham_y)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\pytorch3d\\loss\\chamfer.py:114\u001b[0m, in \u001b[0;36m_chamfer_distance_single_direction\u001b[1;34m(x, y, x_lengths, y_lengths, x_normals, y_normals, weights, point_reduction, norm, abs_cosine)\u001b[0m\n\u001b[0;32m    111\u001b[0m x_nn \u001b[38;5;241m=\u001b[39m knn_points(x, y, lengths1\u001b[38;5;241m=\u001b[39mx_lengths, lengths2\u001b[38;5;241m=\u001b[39my_lengths, norm\u001b[38;5;241m=\u001b[39mnorm, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    112\u001b[0m cham_x \u001b[38;5;241m=\u001b[39m x_nn\u001b[38;5;241m.\u001b[39mdists[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (N, P1)\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_x_heterogeneous:\n\u001b[0;32m    115\u001b[0m     cham_x[x_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# net = PointCloudAE2(point_size, 768).to(device)\n",
    "# net = PointCloudAE(1024, 256).to(device)\n",
    "# net = ConvAutoEncoder(512, 1024).to(device)\n",
    "last_x = None\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance # chamfer distance for calculating point cloud distance\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0005)\n",
    "\n",
    "def train_epoch():\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = data['points'].to(device)\n",
    "\n",
    "        # x = data.to(device)\n",
    "        output = net(x.permute(0,2,1)) # transpose data for NumberxChannelxSize format\n",
    "        # print(x.shape, output.shape)\n",
    "        loss, _ = chamfer_distance(x, output) \n",
    "        # loss = F.mse_loss(x, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    if i == 0:\n",
    "        return epoch_loss / 1\n",
    "    last_x = x.permute(0,2,1)\n",
    "    return epoch_loss/i\n",
    "\n",
    "\n",
    "train_loss_list = []  \n",
    "test_loss_list = []  \n",
    "\n",
    "for i in range(10000) :\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    train_loss = train_epoch() #train one epoch, get the average loss\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    \n",
    "    epoch_time = time.time() - startTime\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f'Epoch {i} Train_loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_models/furniture_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'trained_models/furniture_model_weights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('trained_models/furniture_model_weights_50k', weights_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = next(iter(train_loader))['points']\n",
    "\n",
    "# cloud = pc.get_point_cloud(x[0])\n",
    "# pc.visualize_point_cloud(cloud)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     data = x.permute(0,2,1).to(device)\n",
    "#     rec_x = np.array(net(data)[0].to('cpu'))\n",
    "#     cloud = pc.get_point_cloud(rec_x)\n",
    "#     pc.visualize_point_cloud(cloud)\n",
    "\n",
    "x = next(iter(test_loader))['points']\n",
    "\n",
    "cloud = pc.get_point_cloud(x[0])\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = x.permute(0,2,1).to(device)\n",
    "    rec_x = np.array(net(data)[0].to('cpu'))\n",
    "    cloud = pc.get_point_cloud(rec_x)\n",
    "    pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 2048])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m     rec_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     11\u001b[0m     cloud \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mget_point_cloud(rec_x)\n\u001b[0;32m     12\u001b[0m     pc\u001b[38;5;241m.\u001b[39mvisualize_point_cloud(cloud)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[56], line 112\u001b[0m, in \u001b[0;36mConvAutoEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 112\u001b[0m     latent_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     recontructed_cloud \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(latent_rep)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recontructed_cloud\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[56], line 35\u001b[0m, in \u001b[0;36mConvEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn6(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc6(x)))\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mint\u001b[39m(point_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m )\n\u001b[1;32m---> 35\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mgelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn7\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin7\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin8(x)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\functional.py:2810\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2798\u001b[0m         batch_norm,\n\u001b[0;32m   2799\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2807\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m   2808\u001b[0m     )\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m-> 2810\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m   2813\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2814\u001b[0m     weight,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2821\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled,\n\u001b[0;32m   2822\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\zfogg\\anaconda3\\envs\\test-open3d\\lib\\site-packages\\torch\\nn\\functional.py:2776\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2774\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   2775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 2776\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2777\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2778\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 2048])"
     ]
    }
   ],
   "source": [
    "model = net\n",
    "x = next(iter(test_loader))['points'][0]\n",
    "\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "    rec_x = np.array(model(data)[0].to('cpu'))\n",
    "    cloud = pc.get_point_cloud(rec_x)\n",
    "    pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = next(iter(train_loader))['points'][0][0:50]\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5825, 0.5014, 0.1379],\n",
       "        [0.5915, 0.4976, 0.1370],\n",
       "        [0.8215, 0.3296, 0.1172],\n",
       "        ...,\n",
       "        [0.6037, 0.3774, 0.0789],\n",
       "        [0.6028, 0.3761, 0.0731],\n",
       "        [0.6030, 0.3761, 0.0733]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_size = 768\n",
    "train_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'train', object_classes=['stool', 'chair', 'tv_stand', 'bench', 'desk'])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "class PointCloudAE(nn.Module):\n",
    "    def __init__(self, point_size, latent_size):\n",
    "        super(PointCloudAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        self.point_size = point_size\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 256, 1)\n",
    "        self.lin1 = nn.Linear(self.point_size, self.latent_size)\n",
    "        self.lin2 = nn.Linear(self.latent_size, 1)\n",
    "        # self.bn1 = nn.BatchNorm1d(128)\n",
    "        # self.bn2 = nn.BatchNorm1d(256)\n",
    "        # self.bn3 = nn.BatchNorm1d(256)\n",
    "        # self.bn4 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "\n",
    "        self.dec1 = nn.Linear(self.latent_size,self.point_size)\n",
    "        self.dec2 = nn.Linear(self.point_size,2048)\n",
    "        self.dec3 = nn.Linear(2048, 3072)\n",
    "        self.dec4 = nn.Linear(3072,self.point_size*3)\n",
    "\n",
    "    def encoder(self, x): \n",
    "        # x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # x = F.relu(self.bn3(self.conv3(x)))\n",
    "        # x = F.relu(self.bn4(self.lin1(x)))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        x = x.view(-1, self.latent_size)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = self.dec4(x)\n",
    "        x = x.view(-1, self.point_size, 3)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-open3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
