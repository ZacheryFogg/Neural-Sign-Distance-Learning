{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "#from pytorch3d.loss import chamfer_distance\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "#from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from Helpers.data import PointCloudDataset\n",
    "from Helpers.repair_dataset import repair_off_files\n",
    "import Helpers.PointCloudOpen3d as pc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f'Using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../Data/ModelNet40\"\n",
    "repair_off_files(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889\n"
     ]
    }
   ],
   "source": [
    "point_size = 1024\n",
    "object_classes= ['chair']#['stool', 'chair', 'tv_stand', 'bench', 'desk', 'sofa', 'wardrobe', 'toilet', 'table', 'sink', 'night_stand', 'mantel','dresser', 'bookshelf','bed']\n",
    "train_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'train', object_classes=object_classes)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "# test_dataset = PointCloudDataset(\"../Data/ModelNet40\", point_size, 'test', object_classes=object_classes)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "# print(len(test_dataset))\n",
    "print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudAE(nn.Module):\n",
    "    def __init__(self, point_size, latent_size):\n",
    "        super(PointCloudAE, self).__init__()\n",
    "        \n",
    "        self.latent_size = latent_size\n",
    "        self.point_size = point_size\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, self.latent_size, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(self.latent_size)\n",
    "        \n",
    "        self.dec1 = nn.Linear(self.latent_size,256)\n",
    "        self.dec2 = nn.Linear(256,256)\n",
    "        self.dec3 = nn.Linear(256,self.point_size*3)\n",
    "\n",
    "    def encoder(self, x): \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, self.latent_size)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = self.dec3(x)\n",
    "        return x.view(-1, self.point_size, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_distance(x, y):\n",
    "    \"\"\"\n",
    "    Compute Chamfer Distance between two point clouds x and y.\n",
    "    x: (batch_size, n_points, 3)\n",
    "    y: (batch_size, m_points, 3)\n",
    "    Returns: Chamfer distance loss (a scalar)\n",
    "    \"\"\"\n",
    "    # Compute pairwise Euclidean distance between points in x and y\n",
    "    dist = torch.cdist(x, y, p=2)  # dist: (batch_size, n_points, m_points)\n",
    "    \n",
    "    # Find the minimum distance from each point in x to y\n",
    "    dist1, _ = torch.min(dist, dim=2)  # (batch_size, n_points), min distances for x to y\n",
    "    \n",
    "    # Find the minimum distance from each point in y to x\n",
    "    dist2, _ = torch.min(dist, dim=1)  # (batch_size, m_points), min distances for y to x\n",
    "    \n",
    "    # Chamfer Distance = average of both directions\n",
    "    chamfer_loss = torch.mean(dist1) + torch.mean(dist2)\n",
    "    return chamfer_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.6768216215647184\n",
      "Epoch: 10 Loss: 0.13773161860612723\n",
      "Epoch: 20 Loss: 0.10007947511397876\n",
      "Epoch: 30 Loss: 0.09124401383675061\n",
      "Epoch: 40 Loss: 0.08557815677844562\n",
      "Epoch: 50 Loss: 0.08477511428869687\n",
      "Epoch: 60 Loss: 0.08347640931606293\n",
      "Epoch: 70 Loss: 0.08144808961794926\n",
      "Epoch: 80 Loss: 0.07883809334956683\n",
      "Epoch: 90 Loss: 0.08115584861773711\n",
      "Epoch: 100 Loss: 0.07646366667289001\n",
      "Epoch: 110 Loss: 0.07833686241736779\n",
      "Epoch: 120 Loss: 0.07460961605493839\n",
      "Epoch: 130 Loss: 0.07318866023650536\n",
      "Epoch: 140 Loss: 0.07365244512374584\n",
      "Epoch: 150 Loss: 0.07100835729103822\n",
      "Epoch: 160 Loss: 0.07228594789138207\n",
      "Epoch: 170 Loss: 0.0715901109461601\n",
      "Epoch: 180 Loss: 0.07256328113950215\n",
      "Epoch: 190 Loss: 0.06879754994924252\n",
      "Epoch: 200 Loss: 0.06993510917975353\n",
      "Epoch: 210 Loss: 0.0686522197838013\n",
      "Epoch: 220 Loss: 0.06909783786306015\n",
      "Epoch: 230 Loss: 0.06866265890689996\n",
      "Epoch: 240 Loss: 0.06885016738222195\n",
      "Epoch: 250 Loss: 0.06565688607784417\n",
      "Epoch: 260 Loss: 0.06836459843012002\n",
      "Epoch: 270 Loss: 0.0663820614035313\n",
      "Epoch: 280 Loss: 0.06575207670147602\n",
      "Epoch: 290 Loss: 0.0683291654747266\n",
      "Epoch: 300 Loss: 0.06599514587567402\n",
      "Epoch: 310 Loss: 0.06685170416648571\n",
      "Epoch: 320 Loss: 0.06871412665798114\n",
      "Epoch: 330 Loss: 0.06561568837899429\n",
      "Epoch: 340 Loss: 0.06465575500176503\n",
      "Epoch: 350 Loss: 0.0645284910614674\n",
      "Epoch: 360 Loss: 0.06425019726157188\n",
      "Epoch: 370 Loss: 0.0644818667608958\n",
      "Epoch: 380 Loss: 0.06299454403611329\n",
      "Epoch: 390 Loss: 0.0625785792676302\n",
      "Epoch: 400 Loss: 0.06164121341246825\n",
      "Epoch: 410 Loss: 0.06561903426280388\n",
      "Epoch: 420 Loss: 0.06201111897826195\n",
      "Epoch: 430 Loss: 0.06457729265093803\n",
      "Epoch: 440 Loss: 0.061500536707731396\n",
      "Epoch: 450 Loss: 0.06302995005479226\n",
      "Epoch: 460 Loss: 0.06158108120927444\n",
      "Epoch: 470 Loss: 0.061222680199604765\n",
      "Epoch: 480 Loss: 0.06132267415523529\n",
      "Epoch: 490 Loss: 0.06169593219573681\n",
      "Epoch: 500 Loss: 0.06141666609507341\n",
      "Epoch: 510 Loss: 0.06097523151681973\n",
      "Epoch: 520 Loss: 0.062418823345349386\n",
      "Epoch: 530 Loss: 0.06127604125783993\n",
      "Epoch: 540 Loss: 0.06286068317981866\n",
      "Epoch: 550 Loss: 0.05952389251727324\n",
      "Epoch: 560 Loss: 0.059984404020584546\n",
      "Epoch: 570 Loss: 0.05965127108188776\n",
      "Epoch: 580 Loss: 0.06012917424623783\n",
      "Epoch: 590 Loss: 0.059574940170233064\n",
      "Epoch: 600 Loss: 0.05901430891110347\n",
      "Epoch: 610 Loss: 0.0591135870378751\n",
      "Epoch: 620 Loss: 0.05904702842235565\n",
      "Epoch: 630 Loss: 0.05751874870978869\n",
      "Epoch: 640 Loss: 0.059536256469213046\n",
      "Epoch: 650 Loss: 0.05773075412099178\n",
      "Epoch: 660 Loss: 0.05913151915256794\n",
      "Epoch: 670 Loss: 0.059227312700106546\n",
      "Epoch: 680 Loss: 0.058743133854407534\n",
      "Epoch: 690 Loss: 0.058129433829050794\n",
      "Epoch: 700 Loss: 0.05880232327259504\n",
      "Epoch: 710 Loss: 0.059024119606384866\n",
      "Epoch: 720 Loss: 0.057691681843537554\n",
      "Epoch: 730 Loss: 0.05737002795705429\n",
      "Epoch: 740 Loss: 0.058172800219975986\n",
      "Epoch: 750 Loss: 0.0574170548755389\n",
      "Epoch: 760 Loss: 0.05728033758126772\n",
      "Epoch: 770 Loss: 0.05638310685753822\n",
      "Epoch: 780 Loss: 0.05587416829971167\n",
      "Epoch: 790 Loss: 0.05867512380847564\n",
      "Epoch: 800 Loss: 0.056050158463991605\n",
      "Epoch: 810 Loss: 0.05706509431967369\n",
      "Epoch: 820 Loss: 0.05908886572489372\n",
      "Epoch: 830 Loss: 0.0563767202771627\n",
      "Epoch: 840 Loss: 0.05519811694438641\n",
      "Epoch: 850 Loss: 0.05576286780146452\n",
      "Epoch: 860 Loss: 0.05579364844239675\n",
      "Epoch: 870 Loss: 0.05659441793194184\n",
      "Epoch: 880 Loss: 0.055149684445216104\n",
      "Epoch: 890 Loss: 0.05492800502822949\n",
      "Epoch: 900 Loss: 0.05505888078075189\n",
      "Epoch: 910 Loss: 0.055263557399694734\n",
      "Epoch: 920 Loss: 0.05872008691613491\n",
      "Epoch: 930 Loss: 0.055201974052649275\n",
      "Epoch: 940 Loss: 0.054524295032024384\n",
      "Epoch: 950 Loss: 0.05512061113348374\n",
      "Epoch: 960 Loss: 0.05652610757029974\n",
      "Epoch: 970 Loss: 0.05574090234362162\n",
      "Epoch: 980 Loss: 0.05482172306913596\n",
      "Epoch: 990 Loss: 0.05556076593123949\n",
      "Epoch: 1000 Loss: 0.05390493399821795\n",
      "Epoch: 1010 Loss: 0.05470508021804003\n",
      "Epoch: 1020 Loss: 0.053873918377436124\n",
      "Epoch: 1030 Loss: 0.05500798701093747\n",
      "Epoch: 1040 Loss: 0.05370561692577142\n",
      "Epoch: 1050 Loss: 0.05398131964298395\n",
      "Epoch: 1060 Loss: 0.05462409756504572\n",
      "Epoch: 1070 Loss: 0.052780852294885196\n",
      "Epoch: 1080 Loss: 0.05513991644749275\n",
      "Epoch: 1090 Loss: 0.0544408462368525\n",
      "Epoch: 1100 Loss: 0.05347407322663527\n",
      "Epoch: 1110 Loss: 0.05246477029644526\n",
      "Epoch: 1120 Loss: 0.05385729699180676\n",
      "Epoch: 1130 Loss: 0.05416438069481116\n",
      "Epoch: 1140 Loss: 0.05460604910667126\n",
      "Epoch: 1150 Loss: 0.05434089698470556\n",
      "Epoch: 1160 Loss: 0.05501127013793358\n",
      "Epoch: 1170 Loss: 0.054873399723034635\n",
      "Epoch: 1180 Loss: 0.053774245943014436\n",
      "Epoch: 1190 Loss: 0.05472063960937353\n",
      "Epoch: 1200 Loss: 0.05515698085610683\n",
      "Epoch: 1210 Loss: 0.053948260843753815\n",
      "Epoch: 1220 Loss: 0.05436473597700779\n",
      "Epoch: 1230 Loss: 0.05328570965390939\n",
      "Epoch: 1240 Loss: 0.05246542623409858\n",
      "Epoch: 1250 Loss: 0.054514979800352685\n",
      "Epoch: 1260 Loss: 0.05286614023722135\n",
      "Epoch: 1270 Loss: 0.052124953613831446\n",
      "Epoch: 1280 Loss: 0.052199374311245404\n",
      "Epoch: 1290 Loss: 0.053957314731983036\n",
      "Epoch: 1300 Loss: 0.05216825352265285\n",
      "Epoch: 1310 Loss: 0.051863331347703934\n",
      "Epoch: 1320 Loss: 0.052583009004592896\n",
      "Epoch: 1330 Loss: 0.05269686505198479\n",
      "Epoch: 1340 Loss: 0.05176750541879581\n",
      "Epoch: 1350 Loss: 0.051566838645018064\n",
      "Epoch: 1360 Loss: 0.053133898629592016\n",
      "Epoch: 1370 Loss: 0.051630725081150346\n",
      "Epoch: 1380 Loss: 0.051897243524973206\n",
      "Epoch: 1390 Loss: 0.052837284425130256\n",
      "Epoch: 1400 Loss: 0.051368336838025316\n",
      "Epoch: 1410 Loss: 0.052874731902892776\n",
      "Epoch: 1420 Loss: 0.051604840331352674\n",
      "Epoch: 1430 Loss: 0.051642415615228504\n",
      "Epoch: 1440 Loss: 0.05178048060490535\n",
      "Epoch: 1450 Loss: 0.051191722257779196\n",
      "Epoch: 1460 Loss: 0.054262868200357146\n",
      "Epoch: 1470 Loss: 0.05294193871892416\n",
      "Epoch: 1480 Loss: 0.05098375563438122\n",
      "Epoch: 1490 Loss: 0.05196339178543825\n",
      "Epoch: 1500 Loss: 0.051664821803569794\n",
      "Epoch: 1510 Loss: 0.05077425247201553\n",
      "Epoch: 1520 Loss: 0.051066009471049674\n",
      "Epoch: 1530 Loss: 0.05242637029060951\n",
      "Epoch: 1540 Loss: 0.05027621927169653\n",
      "Epoch: 1550 Loss: 0.051055406721738666\n",
      "Epoch: 1560 Loss: 0.0495482304921517\n",
      "Epoch: 1570 Loss: 0.05022952820246036\n",
      "Epoch: 1580 Loss: 0.05123722925782204\n",
      "Epoch: 1590 Loss: 0.05072957477890528\n",
      "Epoch: 1600 Loss: 0.05140906199812889\n",
      "Epoch: 1610 Loss: 0.05084114521741867\n",
      "Epoch: 1620 Loss: 0.050206358616168685\n",
      "Epoch: 1630 Loss: 0.051071963631189786\n",
      "Epoch: 1640 Loss: 0.049550010034671195\n",
      "Epoch: 1650 Loss: 0.051048801495478704\n",
      "Epoch: 1660 Loss: 0.05048690621669476\n",
      "Epoch: 1670 Loss: 0.049959178727406725\n",
      "Epoch: 1680 Loss: 0.05132911698176311\n",
      "Epoch: 1690 Loss: 0.050320523289533764\n",
      "Epoch: 1700 Loss: 0.0510905201618488\n",
      "Epoch: 1710 Loss: 0.05309252469585492\n",
      "Epoch: 1720 Loss: 0.05033887149049686\n",
      "Epoch: 1730 Loss: 0.04967828925985556\n",
      "Epoch: 1740 Loss: 0.050559741946367115\n",
      "Epoch: 1750 Loss: 0.04871643277314993\n",
      "Epoch: 1760 Loss: 0.050199680316906706\n",
      "Epoch: 1770 Loss: 0.051288798451423645\n",
      "Epoch: 1780 Loss: 0.050682163009276755\n",
      "Epoch: 1790 Loss: 0.05096604703710629\n",
      "Epoch: 1800 Loss: 0.049357774739082046\n",
      "Epoch: 1810 Loss: 0.0491745423239011\n",
      "Epoch: 1820 Loss: 0.04965632466169504\n",
      "Epoch: 1830 Loss: 0.04933305142017511\n",
      "Epoch: 1840 Loss: 0.049138278915331915\n",
      "Epoch: 1850 Loss: 0.04882311104581906\n",
      "Epoch: 1860 Loss: 0.050445553488456286\n",
      "Epoch: 1870 Loss: 0.048611704260110855\n",
      "Epoch: 1880 Loss: 0.049317510368732304\n",
      "Epoch: 1890 Loss: 0.04990390831461319\n",
      "Epoch: 1900 Loss: 0.05068771770367256\n",
      "Epoch: 1910 Loss: 0.04981038461510952\n",
      "Epoch: 1920 Loss: 0.04893993041836298\n",
      "Epoch: 1930 Loss: 0.05247022555424617\n",
      "Epoch: 1940 Loss: 0.04967197317343492\n",
      "Epoch: 1950 Loss: 0.051765345610105075\n",
      "Epoch: 1960 Loss: 0.050142488800562345\n",
      "Epoch: 1970 Loss: 0.05128259183122562\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net = PointCloudAE(1024, 256).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0001)\n",
    "\n",
    "def train_epoch():\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = data['points'].to(device)\n",
    "\n",
    "        output = net(x.permute(0,2,1)) # transpose data for NumberxChannelxSize format\n",
    "\n",
    "        loss = chamfer_distance(x, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    if i == 0:\n",
    "        return epoch_loss / 1\n",
    "    return epoch_loss/i\n",
    "\n",
    "\n",
    "train_loss_list = []  \n",
    "test_loss_list = []  \n",
    "\n",
    "for i in range(10000) :\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    train_loss = train_epoch() #train one epoch, get the average loss\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    \n",
    "    epoch_time = time.time() - startTime\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {i} Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_models/furniture_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'trained_models/furniture_model_weights_50k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('trained_models/furniture_model_weights_50k', weights_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "x = next(iter(train_loader))['points'][0]\n",
    "\n",
    "cloud = pc.get_point_cloud(x[:1000])\n",
    "pc.visualize_point_cloud(cloud)\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "    rec_x = np.array(model(data)[0].to('cpu'))\n",
    "    cloud = pc.get_point_cloud(rec_x)\n",
    "    pc.visualize_point_cloud(cloud)\n",
    "# x = next(iter(train_loader))['points'][0]\n",
    "\n",
    "# cloud = pc.get_point_cloud(x)\n",
    "# pc.visualize_point_cloud(cloud)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "#     rec_x = np.array(model(data)[0].to('cpu'))\n",
    "#     cloud = pc.get_point_cloud(rec_x)\n",
    "#     pc.visualize_point_cloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net\n",
    "x = next(iter(test_loader))['points'][0]\n",
    "\n",
    "cloud = pc.get_point_cloud(x)\n",
    "pc.visualize_point_cloud(cloud)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = x.unsqueeze(0).permute(0,2,1).to(device)\n",
    "\n",
    "    rec_x = np.array(model(data)[0].to('cpu'))\n",
    "    cloud = pc.get_point_cloud(rec_x)\n",
    "    pc.visualize_point_cloud(cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "78f5f5f49bfb79eff1b75f7af9e6efc3fcb545b54f444bc1ad589308dff7b92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
