{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import open3d as o3d\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(f'Using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self,base_dir, point_cloud_size = 1000, split = 'train'):\n",
    "\n",
    "        self.point_cloud_size = point_cloud_size\n",
    "        self.point_clouds = None\n",
    "        self.split = split\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "        self.files = self.get_file_paths(self.split, self.base_dir)\n",
    "        self.point_clouds = self.get_uniform_point_clouds(self.split)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.point_clouds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"points\": self.point_clouds[idx],\n",
    "            \"filename\" : self.files[idx]\n",
    "        }\n",
    "    \n",
    "    def get_file_paths(self, split, base_dir):\n",
    "        '''\n",
    "        Return list of all filepaths in ModelNet40 that are part of split (train or test)\n",
    "        '''\n",
    "        file_paths = []\n",
    "        for root, _, files in os.walk(base_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.off'):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    if f'/{split}/' in full_path:\n",
    "                        file_paths.append(full_path)\n",
    "        return file_paths\n",
    "    \n",
    "    \n",
    "    def get_uniform_point_clouds(self, split):\n",
    "        '''\n",
    "        Return a tensor that is all point clouds of fixed size\n",
    "        '''\n",
    "\n",
    "        point_clouds_list = []\n",
    "        for file in self.files: \n",
    "            mesh = o3d.io.read_triangle_mesh(file)\n",
    "            try: \n",
    "                sampled_point_cloud = mesh.sample_points_uniformly(number_of_points = self.point_cloud_size)\n",
    "                point_clouds_list.append(torch.tensor(np.asanyarray(sampled_point_cloud.points),dtype = torch.float32))\n",
    "            except RuntimeError: # Some .OFF files are damaged, run repair script\n",
    "                print(f'Damaged file: {file}')\n",
    "\n",
    "        return point_clouds_list\n",
    "        \n",
    "        \n",
    "dataset = PointCloudDataset(base_dir = \"../ModelNet40\")\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MLPEncoder(nn.Module):\n",
    "\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.fc1 = nn.Linear(config.input_dim, config.hidden_dim1)\n",
    "#         self.fc2 = nn.Linear(config.hidden_dim1, config.hidden_dim2)\n",
    "#         self.fc3 = nn.Linear(config.hidden_dim2, config.latent_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.gelu(self.fc1(x))\n",
    "#         x = F.gelu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# class MLPDecoder(nn.Module):\n",
    "\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.fc1 = nn.Linear(config.latent_dim, config.hidden_dim2)\n",
    "#         self.fc2 = nn.Linear(config.hidden_dim2, config.hidden_dim1)\n",
    "#         self.fc3 = nn.Linear(config.hidden_dim1, config.input_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.gelu(self.fc1(x))\n",
    "#         x = F.gelu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Autoencoder(nn.Module):\n",
    "\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.encoder = MLPEncoder(config)\n",
    "#         self.decoder = MLPDecoder(config)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         latent_rep = self.encoder(x)\n",
    "#         out = self.decoder(latent_rep)\n",
    "#         return out\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(config.input_dim, config.input_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = self.fc(x)\n",
    "        return x + (.00001 * y)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   Epoch Loss: 1359899964.831061\n",
      "Epoch 1   Epoch Loss: 4864357849.294123\n",
      "Epoch 2   Epoch Loss: 8762562699.149101\n",
      "Epoch 3   Epoch Loss: 7538794729.141841\n",
      "Epoch 4   Epoch Loss: 6088163790.689809\n",
      "Epoch 5   Epoch Loss: 5902926931.395541\n",
      "Epoch 6   Epoch Loss: 6470063842.453177\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     48\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 50\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     batch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "point_cloud_size = 1000 \n",
    "\n",
    "\n",
    "# @dataclass \n",
    "# class MLPAutoEncoderConfig:\n",
    "#     input_dim = point_cloud_size * 3\n",
    "#     hidden_dim1 = 3072\n",
    "#     hidden_dim2 = 2048\n",
    "#     latent_dim = 768\n",
    "\n",
    "@dataclass \n",
    "class MLPAutoEncoderConfig:\n",
    "    input_dim = point_cloud_size * 3\n",
    "    hidden_dim1 = point_cloud_size * 3\n",
    "    hidden_dim2 = point_cloud_size * 3\n",
    "    latent_dim = point_cloud_size * 3\n",
    "\n",
    "\n",
    "config = MLPAutoEncoderConfig()\n",
    "\n",
    "model = Autoencoder(config).to(device)\n",
    "\n",
    "optim = torch.optim.AdamW(model.parameters(), lr= 1e-4)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "report_rate = 600\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0 \n",
    "\n",
    "    batch_count = 0 \n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "\n",
    "        x = data['points']\n",
    "        x = x.view(x.shape[0], -1).to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = F.mse_loss(pred, x)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        batch_count +=1\n",
    "\n",
    "    print(f'Epoch {epoch:<3} Epoch Loss: {running_loss / batch_count}')\n",
    "\n",
    "        # if i % report_rate == report_rate - 1:\n",
    "        #     print(f'Batch {i:<3} Running Loss: {running_loss / report_rate}')\n",
    "        #     running_loss = 0\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 15000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(x.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
