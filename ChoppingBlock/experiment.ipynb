{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import json\n",
    "\n",
    "\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Helpers.data import SDDataset, PointCloudDataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f'Using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainset, '../Data/sd_dataset_3072_train_easier')\n",
    "torch.save(testset, '../Data/sd_dataset_3072_test_easier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.load('../Data/sd_dataset_3072_train_easier.pt', weights_only= False)\n",
    "testset = torch.load('../Data/sd_dataset_3072_test_easier.pt', weights_only= False)\n",
    "# trainset = SDDataset('../Data/ModelNet40', '../Data/sampled_points_easier', device, 3072, 'train', object_classes= None)\n",
    "# testset = SDDataset('../Data/ModelNet40', '../Data/sampled_points_easier', device, 3072, 'test', object_classes= None)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size= batch_size, shuffle= True)\n",
    "test_loader = DataLoader(testset, batch_size= batch_size, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(key, model, num_epochs, train_loader, val_loader):\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "    min_val_loss = np.inf\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train one epoch\n",
    "        train_loss = 0 \n",
    "        \n",
    "        count = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            \n",
    "            latent_rep = data['latent_rep'].to(device)\n",
    "            xyz = data['xyz'].to(device)\n",
    "            sd = (data['sd'] > 0).float().to(device)\n",
    "\n",
    "            pred = model(latent_rep, xyz)\n",
    "            pred = pred.squeeze()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = F.binary_cross_entropy_with_logits(pred, sd)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if count % 50000 == 0:\n",
    "                print(f'{count}: {loss.item()}')\n",
    "\n",
    "            count +=1\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Calculate validation loss\n",
    "\n",
    "        val_loss = 0 \n",
    "\n",
    "        for data in val_loader:\n",
    "\n",
    "            latent_rep = data['latent_rep'].to(device)\n",
    "            xyz = data['xyz'].to(device)\n",
    "            # sd = data['sd'].to(device)\n",
    "            sd = (data['sd'] >  0).float().to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = model(latent_rep, xyz)\n",
    "                pred = pred.squeeze()\n",
    "\n",
    "                loss = F.binary_cross_entropy_with_logits(pred, sd)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1} \\t Train Loss: {train_loss:.5f} \\t Val Loss: {val_loss:.5f}')\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < min_val_loss:\n",
    "            print(f'Val Loss Decreased({min_val_loss:.6f} ---> {val_loss:.6f}) \\t Saving The Model')\n",
    "            min_val_loss = val_loss\n",
    "\n",
    "            torch.save(model.state_dict(), f'./trained_sdf_models/{key}')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SD_Model_Simple(512)\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "key = \"mlp_512_simple\"\n",
    "train_losses, val_losses = train_model(key, model, num_epochs , train_loader, test_loader)\n",
    "\n",
    "results = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses' : val_losses\n",
    "           }\n",
    "\n",
    "with open(f'./{key}_results.json', 'w') as f: \n",
    "    json.dumps(f, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SD_Model_Small(512)\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "key = \"mlp_512_small\"\n",
    "train_losses, val_losses = train_model(key, model, num_epochs , train_loader, test_loader)\n",
    "\n",
    "results = {\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses' : val_losses\n",
    "           }\n",
    "\n",
    "with open(f'./{key}_results.json', 'w') as f: \n",
    "    json.dumps(f, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-open3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
